# -*- coding: utf-8 -*-
"""class04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10AzJ7sDhGMeiCaMS_JzKfBeMLgT11wZD
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from string import ascii_letters
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# %precision %.2f
pd.options.display.float_format = '{:,.2f}'.format

uri = "https://raw.githubusercontent.com/BiaChacon/data-science-starting/master/datasets/microdados_enem/MICRODADOS_ENEM_2018_SAMPLE_43278.csv"
dados = pd.read_csv(uri)

"""## Desafio 1
Se a pessoa não teve presença, preencha a nota dela com algum número. A nota 0? A nota média? A mediana?
"""

colunas_de_notas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']
dados_notas = dados[colunas_de_notas]

notas_null = dados_notas.query("NU_NOTA_CN.isna() and NU_NOTA_LC.isna() \
and NU_NOTA_CH.isna() and NU_NOTA_MT.isna()", engine="python")
data = dados_notas.drop(notas_null.index)

data.columns = ['ciencias_naturais', 'ciencias_humanas', 'linguagem_codigo', 'matematica', 'redacao']
data.fillna(0, inplace=True)

"""## Desafio 2
A matriz de correlação está feiosa, vamos deixar mais bonita? :) Não se esqueça de manter os valores dentro delas.
"""

corr = data.corr()

mask = np.zeros_like(corr)
mask[np.triu_indices_from(mask)] = True
with sns.axes_style("white"):
    f, ax = plt.subplots(figsize=(11, 9))
    ax = sns.heatmap(corr, mask=mask, vmin=0.5, vmax=0.8, 
    annot=True, square=True)
corr

"""## Desafio 3
Pairplot dos acertos de cada categoria (CN, CH, MT, LC, nota pura da redação). Usar o gabarito e as respostas
"""

def conta_acertos(dado, resps, gabarito):
  cont = [sum(1 for i, j in zip(g, h) if i == j) for g, h in zip(dado[resps], dado[gabarito])]
  return cont

colunas_respostas = ['TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_LC', 
                      'TX_RESPOSTAS_MT', 'TX_GABARITO_CN', 'TX_GABARITO_CH', 
                      'TX_GABARITO_LC', 'TX_GABARITO_MT', 'NU_NOTA_REDACAO']
dados_respostas = dados[colunas_respostas].dropna()                

dados_respostas["CONT_CN"] = conta_acertos(dados_respostas, "TX_RESPOSTAS_CN", "TX_GABARITO_CN")
dados_respostas["CONT_CH"] = conta_acertos(dados_respostas, "TX_RESPOSTAS_CH", "TX_GABARITO_CH")
dados_respostas["CONT_LC"] = conta_acertos(dados_respostas, "TX_RESPOSTAS_LC", "TX_GABARITO_LC")
dados_respostas["CONT_MT"] = conta_acertos(dados_respostas, "TX_RESPOSTAS_MT", "TX_GABARITO_MT")

dados_respostas.drop(columns=['TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT',
                              'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC', 'TX_GABARITO_MT'])
sns.pairplot(dados_respostas)

dados_sem_zero = data.query("ciencias_naturais > 0 and ciencias_humanas > 0  \
                             and linguagem_codigo > 0 and matematica > 0 \
                             and redacao > 0")

"""## Desafio 4
Remover todos os zeros. Tomar o cuidado que no desafio 1 já tomamos decisões ligadas a limpeza dos dados também. Você também pode exportar para outro CSV se quiser.
"""

sns.pairplot(dados_sem_zero)

"""## Desafio 5
Quais questões tiveram mais erros (análise sobre o gabarito x acertos x erros)
"""

def correcao(prova, gabarito, respostas):
  new_cols = list(range(prova[respostas].map(len).max()))
  prova = prova.reindex(columns=[*prova.columns.tolist(),*new_cols], fill_value=0)
  for i, row in prova.iterrows():
    for j, (g, h) in enumerate(zip(row[respostas], row[gabarito])):
      if g == h:
        prova.at[i,j] = 1
  return prova, new_cols

matematica = dados[['TX_GABARITO_MT', 'CO_PROVA_MT', 'TX_RESPOSTAS_MT']].dropna()
matematica, rn = correcao(matematica, 'TX_GABARITO_MT', 'TX_RESPOSTAS_MT')
matematica.groupby("CO_PROVA_MT")[[*rn]].apply(lambda x: x[x == 0].count()/x.count()).describe().head()

linguagens = dados[['TX_GABARITO_LC', 'CO_PROVA_LC', 'TX_RESPOSTAS_LC']].dropna()
linguagens, rn = correcao(linguagens, 'TX_GABARITO_LC', 'TX_RESPOSTAS_LC')
linguagens.groupby("CO_PROVA_LC")[[*rn]].apply(lambda x: x[x == 0].count()/x.count()).describe().head()

humanas = dados[['TX_GABARITO_CH', 'CO_PROVA_CH', 'TX_RESPOSTAS_CH']].dropna()
humanas, rn = correcao(humanas, 'TX_GABARITO_CH', 'TX_RESPOSTAS_CH')
humanas.groupby("CO_PROVA_CH")[[*rn]].apply(lambda x: x[x == 0].count()/x.count()).describe().head()

natureza = dados[['TX_GABARITO_CN', 'CO_PROVA_CN', 'TX_RESPOSTAS_CN']].dropna()
natureza, rn = correcao(natureza, 'TX_GABARITO_CN', 'TX_RESPOSTAS_CN')
natureza.groupby("CO_PROVA_CN")[[*rn]].apply(lambda x: x[x == 0].count()/x.count()).describe().head()

"""## Desafio 6
Estudar o que as pessoas que estudam o assunto estão discutindo e conclusões que já chegaram sobre a utilização de informações (principalmente sensíveis) para machine learning e data science. Podcast do datahackers também sobre o assunto.
"""